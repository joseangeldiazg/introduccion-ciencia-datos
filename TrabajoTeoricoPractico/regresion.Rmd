---
title: "Regresión"
author: "joseangeldiazg"
date: "4/1/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 6 Regresión

En este punto del trabajo final de la asignatura aplicaremos técnicas de regresión sobre los datos analizados en el punto 4, sobre el dataset **autompg8**. Concretamente se pide:

1. Utilizar el algoritmo de regresión lineal simple sobre cada regresor (variable de entrada) para obtener los modelos correspondientes. Si el datasetR asignado incluye más de 5 regresores, seleccione de manera justificada los 5 que considere más relevantes. Una vez obtenidos los modelos, elegir el que considere más adecuado para su conjunto de datos según las medidas de calidad conocidas.

2. Utilizar el algoritmo para regresión lineal múltiple. Justificar adecuadamente si el modelo obtenido aporta mejoras respecto al modelo elegido en el paso anterior (en este apartado tenga también en cuenta la consideración de posibles interacciones y no linealidad).

3. Aplicar el algoritmo k-NN para regresión.

4. Comparar los resultados de los dos algoritmos de regresión múltiple entre sí, y adicionalmente media


## 6.1 Modelos lineales simples

Vamos a construir modelos lineales simples para nuestro dataset. Para ello, nos vasaremos en las cinco variables más correlacionadas negativa o positivamente nuestra variable objetivo. Estas son:

- Cylinders
- Displacement
- Horse_power
- Weight
- Model_year

Crearemos los modelos e interpretaremos sus resultados. 

```{r}
fit1=lm(autompg8$Mpg~as.numeric(autompg8$Cylinders))
summary(fit1)
plot(autompg8$Mpg~as.numeric(autompg8$Cylinders))
abline(fit1,col="red") 
```

Vemos que nuestro modelo no ajusta del todo bien, pero ya se obtienen valores de error aceptables que sin lugar a dudas al ser combinados en modelos más complejos ofrecerán buenos resultados. 

Seguiremos probando ahora con las demás variables correlacionadas con la variable dependiente. 

```{r}
fit2=lm(autompg8$Mpg~autompg8$Displacement)
summary(fit2)
plot(autompg8$Mpg~autompg8$Displacement)
abline(fit2,col="red") 
```

```{r}
fit3=lm(autompg8$Mpg~autompg8$Horse_power)
summary(fit3)
plot(autompg8$Mpg~autompg8$Horse_power)
abline(fit3,col="red") 
```

```{r}
fit4=lm(autompg8$Mpg~autompg8$Weight)
summary(fit4)
plot(autompg8$Mpg~autompg8$Weight)
abline(fit4,col="red") 
```

```{r}
fit5=lm(autompg8$Mpg~as.numeric(autompg8$Model_year))
summary(fit5)
plot(autompg8$Mpg~as.numeric(autompg8$Model_year))
abline(fit5,col="red") 
```

Vemos que ajustan bastante bien, pero cabe destacar que si pudieramos obtener un modelo no lineal seguramente conseguiriamos eliminar el error en gran medida, ya que una curva ajustaría mucho mejor con las anteriores variables, de igual modo, basandonos en el valor del R-Squared (ya que solo estamos usando una variable predictora), nuestra candidata sería el modelo **fit4**, donde hemos tenido en cuenta la variable **Weigth** para inferir la variable objetivo **Mpg** y obtenemos valor de R cuadrado de **0,695**.



## 6.2 Modelos lineales múltiples y no linealidad. 

Tal y como vimos en el punto anterior, podemos concluir que un modelo no lineal ajuste mejor con nuestras variables, por ello probaremos este con las variables **Weight**, **Horse_power**, **Displacement**.

```{r}
fit6<-lm(autompg8$Mpg~autompg8$Weight+I(autompg8$Weight^2))
summary(fit6)
plot(autompg8$Mpg~autompg8$Weight)
points(autompg8$Weight,fitted(fit6),col="red",pch=20)
```


```{r}
fit7<-lm(autompg8$Mpg~autompg8$Displacement+I(autompg8$Displacement^2))
summary(fit7)
plot(autompg8$Mpg~autompg8$Displacement)
points(autompg8$Displacement,fitted(fit7),col="red",pch=20)
```


```{r}
fit8<-lm(autompg8$Mpg~autompg8$Horse_power+I(autompg8$Horse_power^2))
summary(fit8)
plot(autompg8$Mpg~autompg8$Horse_power)
points(autompg8$Horse_power,fitted(fit8),col="red",pch=20)
```

Vemos como estábamos en lo acertado y ahora, hemos ajustado mucho más nuestro modelo llegando con el modelo basado en la variable **Weight** a tener un R-squared de **0.7151**. 

Ahora vamos a generar un modelo basado en regresión lineal múltiple. Para ello, usaremos las 5 variables predictoras que seleccionamos en el proceso de selección de variables. Este modelo, es "secuencial" por lo que iremos añadiendo variables en pequeños pasos para ir comproabando la interacción entre estas. 


```{r}
fit9<-lm(autompg8$Mpg~autompg8$Weight+autompg8$Displacement)
summary(fit9)

fit10<-lm(autompg8$Mpg~autompg8$Weight+autompg8$Displacement+autompg8$Horse_power)
summary(fit10)
```

Vemos como acorde al **p-value**, en este modelo, la variable **Displacement** deja de ser relevante para predecir Mpg, por lo que la obviaremos y dejaremos solo las otras dos. 

```{r}
fit12<-lm(autompg8$Mpg~autompg8$Weight+autompg8$Horse_power)
summary(fit12)
```

Vemos como hemos mejorado alguna milésima, y además, ahora Horse_power, recupera relevancia. Seguiremos añadiendo variables a nuestro modelo multiple para ver si mejora. 

```{r}
fit13<-lm(autompg8$Mpg~autompg8$Weight+autompg8$Horse_power+autompg8$Model_year+autompg8$Origin)
summary(fit13)
```

Parece que al al añadir nuestras variables **Model_year** y **Origin**, el modelo mejora bastante.Por último, vamos a probar que pasaría si usaramos todas las variables del modelo y que pasaría si al modelo fit13, aplicaramos las transformaciones de no linealidad vistas al inicio de esta sección. 


```{r}
fit14<-lm(Mpg~.,data=autompg8)
summary(fit14)
```

Parece que obtenemos grandes resultados y una mejora muy clara respecto a usar solo algunas variables, vemos como las variables que consideramos importantes siguen siendolo. Comprobaremos ahora que pasaría si aplicaramos las transformaciones. 

```{r}
fit15<-lm(Mpg~Cylinders+Displacement+I(Displacement^2)+Horse_power+I(Horse_power^2)+Weight+I(Weight^2)+Model_year+Model_year,data=autompg8)
summary(fit15)
```