---
title: "Regresión"
author: "joseangeldiazg"
date: "4/1/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 6 Regresión

En este punto del trabajo final de la asignatura aplicaremos técnicas de regresión sobre los datos analizados en el punto 4, sobre el dataset **autompg8**. Concretamente se pide:

1. Utilizar el algoritmo de regresión lineal simple sobre cada regresor (variable de entrada) para obtener los modelos correspondientes. Si el datasetR asignado incluye más de 5 regresores, seleccione de manera justificada los 5 que considere más relevantes. Una vez obtenidos los modelos, elegir el que considere más adecuado para su conjunto de datos según las medidas de calidad conocidas.

2. Utilizar el algoritmo para regresión lineal múltiple. Justificar adecuadamente si el modelo obtenido aporta mejoras respecto al modelo elegido en el paso anterior (en este apartado tenga también en cuenta la consideración de posibles interacciones y no linealidad).

3. Aplicar el algoritmo k-NN para regresión.

4. Comparar los resultados de los dos algoritmos de regresión múltiple entre sí, y adicionalmente media


## 6.1 Modelos lineales simples

Vamos a construir modelos lineales simples para nuestro dataset. Para ello, nos vasaremos en las cinco variables más correlacionadas negativa o positivamente nuestra variable objetivo. Estas son:

- Cylinders
- Displacement
- Horse_power
- Weight
- Model_year

Crearemos los modelos e interpretaremos sus resultados. 

```{r}
fit1=lm(autompg8$Mpg~as.numeric(autompg8$Cylinders))
summary(fit1)
plot(autompg8$Mpg~as.numeric(autompg8$Cylinders))
abline(fit1,col="red") 
```

Vemos que nuestro modelo no ajusta del todo bien, pero ya se obtienen valores de error aceptables que sin lugar a dudas al ser combinados en modelos más complejos ofrecerán buenos resultados. 

Seguiremos probando ahora con las demás variables correlacionadas con la variable dependiente. 

```{r}
fit2=lm(autompg8$Mpg~autompg8$Displacement)
summary(fit2)
plot(autompg8$Mpg~autompg8$Displacement)
abline(fit2,col="red") 
```

```{r}
fit3=lm(autompg8$Mpg~autompg8$Horse_power)
summary(fit3)
plot(autompg8$Mpg~autompg8$Horse_power)
abline(fit3,col="red") 
```

```{r}
fit4=lm(autompg8$Mpg~autompg8$Weight)
summary(fit4)
plot(autompg8$Mpg~autompg8$Weight)
abline(fit4,col="red") 
```

```{r}
fit5=lm(autompg8$Mpg~as.numeric(autompg8$Model_year))
summary(fit5)
plot(autompg8$Mpg~as.numeric(autompg8$Model_year))
abline(fit5,col="red") 
```

Vemos que ajustan bastante bien, pero cabe destacar que si pudieramos obtener un modelo no lineal seguramente conseguiriamos eliminar el error en gran medida, ya que una curva ajustaría mucho mejor con las anteriores variables, de igual modo, basandonos en el valor del R-Squared (ya que solo estamos usando una variable predictora), nuestra candidata sería el modelo **fit4**, donde hemos tenido en cuenta la variable **Weigth** para inferir la variable objetivo **Mpg** y obtenemos valor de R cuadrado de **0,695**.



## 6.2 Modelos lineales múltiples y no linealidad. 

Tal y como vimos en el punto anterior, podemos concluir que un modelo no lineal ajuste mejor con nuestras variables, por ello probaremos este con las variables **Weight**, **Horse_power**, **Displacement**.

```{r}
fit6<-lm(autompg8$Mpg~autompg8$Weight+I(autompg8$Weight^2))
summary(fit6)
plot(autompg8$Mpg~autompg8$Weight)
points(autompg8$Weight,fitted(fit6),col="red",pch=20)
```


```{r}
fit7<-lm(autompg8$Mpg~autompg8$Displacement+I(autompg8$Displacement^2))
summary(fit7)
plot(autompg8$Mpg~autompg8$Displacement)
points(autompg8$Displacement,fitted(fit7),col="red",pch=20)
```


```{r}
fit8<-lm(autompg8$Mpg~autompg8$Horse_power+I(autompg8$Horse_power^2))
summary(fit8)
plot(autompg8$Mpg~autompg8$Horse_power)
points(autompg8$Horse_power,fitted(fit8),col="red",pch=20)
```

Vemos como estábamos en lo acertado y ahora, hemos ajustado mucho más nuestro modelo llegando con el modelo basado en la variable **Weight** a tener un R-squared de **0.7151**. 



