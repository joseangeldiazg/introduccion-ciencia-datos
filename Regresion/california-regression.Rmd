---
title: "Estudio de Regresión sobre el dataset California"
author: "joseangeldiazg"
date: "1/12/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmarkdown)
```



## Práctica de laboratorio 1 Regresión lineal simple y multiple sobre el dataset California. 


  
En este caso usaremos el dataset California, incluido en los datasets de la Herramienta KEEL. Para ello, lo primero que tendremos que hacer es leer el dataset de una manera un tanto especial. 
  

```{r}
california <- read.csv("datasets/california.dat", comment.char="@")
#Asignación manual
names(california) <- c("Longitude", "Latitude", "HousingMedianAge",
"TotalRooms", "TotalBedrooms", "Population", "Households", "MedianIncome", "MedianHouseValue")
head(california)
```


Una vez nuestro dataset está creado, podemos añadirlo al entorno con *attach* por comodidad a la hora de referenciar a las variables, aunque para facilitar la comprensión del mismo esto no lo haremos.

## Visualización.

Por medio de algunos gráficos, vamos a intentar buscar relaciones entre nuestras variables. Lo primero será usar la funcion pairs par ver que variables pueden resultarnos mas interesantes. 

```{r}
pairs(california)
```


En base al anterior gráfico, podemos crear otros gráficos, con la siguiente función de manera sencilla.

```{r}
temp <- california
plotY <- function(x,y) 
{
  plot(temp[,y]~temp[,x], xlab=paste(names(temp)[x]," X",x,sep=""), ylab=names(temp)[y])
}
```


Acorde a los gráficos visto con la funcion pairs podemos encontrar cierta correlación entre variables. Vamos a dibujar sus gráficos. 



```{r}
plotY(5,4)
plotY(7,4)
```


Como vemos hay correlación lineal, pero si atendemos a los datos, aporta más bien poco ya que son cosas triviales, como a mas personas dentro de la casa mas habitaciones, algo totalmente trivial. 


Vamos a analizar con más detalle las relaciones entre las **variables independienes** y la **variable dependiente** de nuestro problema. 


```{r}
plotY(3,9)
plotY(4,9)
plotY(5,9)
plotY(6,9)
plotY(7,9)
plotY(8,9)
```



Vamos a probar si realizando una transformación logarítmica podemos encontrar mejores relaciones. 

```{r}
logcalifornia <- log(california[3:9])
pairs(logcalifornia)
```


Volvemos a generar los gráficos de nuestros datos en función a la variable dependiente. 

```{r}
plot(logcalifornia$MedianHouseValue~logcalifornia$HousingMedianAge)
plot(logcalifornia$MedianHouseValue~logcalifornia$TotalRooms)
plot(logcalifornia$MedianHouseValue~logcalifornia$TotalBedrooms)
plot(logcalifornia$MedianHouseValue~logcalifornia$Population)
plot(logcalifornia$MedianHouseValue~logcalifornia$Households)
plot(logcalifornia$MedianHouseValue~logcalifornia$MedianIncome)
```


Los datos no son muy reveladores, pero parece que tenemso una buena candidata para el ajuste lineal simple. Esta candidata es el **MedianInCome**.


## Obtención de modelos lineales simples


Vamos a obtener el modelo para **MedianInCome**.

```{r}
fit1=lm(california$MedianHouseValue~california$MedianIncome)
fit1
```

Ahora que hemos construido el modelo simple, vamos a obtener los resultados. 


```{r}
summary(fit1)
plot(california$MedianHouseValue~california$MedianIncome)
abline(fit1,col="red") 
confint(fit1)
```


En la anterior salida, cabe comentar el valor idéntico entre *Adjusted R-squared* y *R-squared*, debido a que solo estamos usando un predictor para nuestro modelo, si usaramos varios, deberíamos decantarnos por el *Adjusted R-squared*, ya que *R-squared* no se ajustaría a la realidad del problema.  


Vamos a probar a crear ahora el modelo con nuestra versión con transformación logarítmica, para ver los resultados. 
```{r}
fitlog=lm(logcalifornia$MedianHouseValue~logcalifornia$MedianIncome)
summary(fitlog)
plot(logcalifornia$MedianHouseValue~logcalifornia$MedianIncome)
abline(fitlog,col="red") 
confint(fitlog)
```


Los datos constatan que nuestra transformación de los datos a logarítmica no ha sido acerdata. Por ello, descartaremos esta medida.

Por último, vamos a calcular manualmente el **error residual**, para prácticar en el acceso de los datos del modelo y comprobar si ofrece resultados similares a los de la función **summary()**.


```{r}
names(fitlog)
sqrt(sum(fitlog$residuals^2)/length(fitlog$residuals))
```


Antes de entrar a predecir con nuestro modelo casos nuevos, vamos a probar con las demás variables ya que es posible que alguna de ellas aunque en el proceso de EDA pareciera que no eran buenas si que lo sean. 


```{r}
fit2<-lm(california$MedianHouseValue~california$HousingMedianAge)
fit3<-lm(california$MedianHouseValue~california$TotalRooms)
fit4<-lm(california$MedianHouseValue~california$TotalBedrooms)
fit5<-lm(california$MedianHouseValue~california$Population)
fit6<-lm(california$MedianHouseValue~california$Households)

summary(fit2)
plot(california$MedianHouseValue~california$HousingMedianAge)
abline(fit2,col="red") 
confint(fit2)   
```


```{r}
summary(fit3)
plot(california$MedianHouseValue~california$TotalRooms)
abline(fit3,col="red") 
confint(fit3)   
```

```{r}
summary(fit4)
plot(california$MedianHouseValue~california$TotalBedrooms)
abline(fit4,col="red") 
confint(fit4)   
```

```{r}
summary(fit5)
plot(california$MedianHouseValue~california$Population)
abline(fit5,col="red") 
confint(fit5)   
```

```{r}
summary(fit6)
plot(california$MedianHouseValue~california$Households)
abline(fit6,col="red") 
confint(fit6)   
```


## Obtención de modelos lineales múltiples

Como hemos podido constatar los modelos simples no son muy reveladores, y la transformacion logaritmica aunque mejora en algunos casos, hace que nuestra mejor variable para el proceso de regresión empeore mas de un 2%. Basandonos en que un buen modelo de regresión deberá incluir a esta variable, vamos a generar modelos lineales múltiples con el fin de mejorar los valores obtenidos.

```{r}
fit1<-lm(california$MedianHouseValue~california$MedianIncome+california$TotalRooms)
summary(fit1)
```





```{r}
fit2<-lm(california$MedianHouseValue~california$MedianIncome+california$HousingMedianAge)
summary(fit2)
```

En este caso, como hemos comentado anteriormente, debemos fijarnos en el valor **Adjusted R-Squared** ya que tenemos dos valores en nuestro modelo. Hemos conseguido mejorar bastante respecto al anterior por lo que parece que el modelo está empezando a comportarse mejor. 


```{r}
fit3<-lm(california$MedianHouseValue~california$MedianIncome+california$TotalBedrooms)
summary(fit3)
```

Mejora algo respecto a la inclusión de solo el valor de Median Income, por lo que parece que es buena candidata para un modelo con las tres. Vamos a seguir probando. 

```{r}
fit3<-lm(california$MedianHouseValue~california$MedianIncome+california$Population)
summary(fit3)
```




```{r}
fit4<-lm(california$MedianHouseValue~california$MedianIncome+california$Households)
summary(fit4)
```


Tenemos por tanto dos claras candidatas para nuestro modelo, estás son: **MedianInCome** y **HousingMedianAge**, por lo tanto, podremos construir modelos con mas variables añadiendo algunas a estas. Para ver cuales añadir y cuales quitar, podemos crear el modelo con todas y ver cuales podemos descartar según su valor de p-value. 


```{r}
fitfinal<-lm(MedianHouseValue~.,data = california)
summary(fitfinal)
```

Parece que todas las variables son relevantes en funcion del p-value, el modelo ha mejorado bastante desde que creamos la priemera aproximación y quitar algún elemento hará que este probablemente empeore ya que todos son considerados relevantes. Vamos a probar con nuestro modelo de transformación logaritmica a ver si ha mejorado algo. 


```{r}
fitlog<-lm(MedianHouseValue~.,data = logcalifornia)
summary(fitlog)
```

Podemos ver que comparándolo con el anterior modelo, este no ofrece tan buenos resultados. Por último calcularemos el error en nuestro modelo. 

### Obtención de error en test de nuestro modelo

Para ascercarnos más a la realidad de un problema dado, crearemos dos particiones del dataset california, una muestra aleatoria y del 20% para test y un 80% para el training.


```{r}
sample <- sample.int(n = nrow(california), size = floor(.75*nrow(california)), replace = F)
train <- california[sample, ]
test  <- california[-sample, ]
```


Ahora con nuestro conjunto de entrenamiento creamos el modelo:

```{r}
trainmodel<-lm(MedianHouseValue~.,data = train)
summary(trainmodel)
```

Por último realizamos predicciones sobre el conjunto de test, que no hemos usado para probar el modelo y calculamos el error de manera manual. 

```{r}
yprime=predict(trainmodel,test)
sqrt(sum(abs(test$MedianHouseValue-yprime)^2)/length(yprime))
```

Podemos ver como el error residual estándard no está muy por debajo que los del conjunto de training, y aunque no es un valor muy bueno, es bastante mejor que cuando comenzamos con nuestro proceso de regresión lineal simple. 

#Práctica de laboratorio 2: Knn y Validación Cruzada


Vamos a usar knn sobre nuestro conjunto de datos, para ello si no lo tenemos debemos instalar el paquete **kknn**.


```{r include=false}
install.packages("kknn")
require(kknn)
```


Una vez instalado el paquete, crearemos el modelo sobre nuestro conjunto de training. 

```{r}
fitknn1<-kknn(MedianHouseValue~., train, test)
```

Una vez creado el modelo, podemos ver los valores si accedemos a *fitknn1$fitted.values*. Para ver manualmente el error podemos realizar lo siguiente:


```{r}
plot(test$MedianHouseValue~test$MedianIncome)
points(test$MedianIncome, fitknn1$fitted.values, col="blue", pch=20)
```


Podemos ver como la prediccion se ajusta bastante bien sobre lo0s datos reales, por lo que graficamente hemos comprobado el funcionamiento del modelo. También podemos caluclar el valor del error, para ello:

```{r}
yprime<-fitknn1$fitted.values
sqrt(sum((test$MedianHouseValue-yprime)^2)/length(yprime))
```

El resultado es algo mejor que el de nuestro modelo lineal múltiple. Pero quizá aún podamos mejorarlo realizando algún tipo de modificación sobre las variables independientes.


```{r}
fitknn2<-kknn(MedianHouseValue~.-HousingMedianAge, train, test)
yprime<-fitknn2$fitted.values
sqrt(sum((test$MedianHouseValue-yprime)^2)/length(yprime))
```

Hemos eliminado nuestra variable HousingMedianAge, del modelo, y parece que funciona un poco mejor. Con esto queda constatado, que aunque tengamos un buen modelo entre dos variables entre si, no se debe descartar la opción de probar que pasaría con los resultados si eliminamos una de ellas. 

### Validación cruzada. 

Para evitar que nuestro modelo sobre-entrene, vamnos a realizar un proceso de validacion cruzada. 

```{r}
setwd("~/Desktop/MASTER CIENCIA DE DATOS/introduccion-ciencia-datos/Regresion/datasets/5fold")
nombre <- "california"
run_lm_fold <- function(i, x, tt = "test") 
{
  file <- paste(x, "-5-", i, "tra.dat", sep="")
  x_tra <- read.csv(file, comment.char="@") 
  file <- paste(x, "-5-", i, "tst.dat", sep="")
  x_tst <- read.csv(file, comment.char="@")
  In <- length(names(x_tra)) - 1 
  names(x_tra)[1:In] <- paste ("X", 1:In, sep="") 
  names(x_tra)[In+1] <- "Y"
  names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tst)[In+1] <- "Y"
  if (tt == "train") 
  {
    test <- x_tra
  } 
  else
  {
    test <- x_tst
  }
  fitMulti=lm(Y~.,x_tra)
  yprime=predict(fitMulti,test)
  sum(abs(test$Y-yprime)^2)/length(yprime)
}
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train")) 
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))

lmMSEtrain
lmMSEtest
```


Ahora lo aplicaremos para el algoritmo KNN:

```{r}
setwd("~/Desktop/MASTER CIENCIA DE DATOS/introduccion-ciencia-datos/Regresion/datasets/5fold")
nombre <- "california"
run_knn_fold <- function(i, x, tt = "test") 
{
  file <- paste(x, "-5-", i, "tra.dat", sep="")
  x_tra <- read.csv(file, comment.char="@") 
  file <- paste(x, "-5-", i, "tst.dat", sep="")
  x_tst <- read.csv(file, comment.char="@")
  In <- length(names(x_tra)) - 1 
  names(x_tra)[1:In] <- paste ("X", 1:In, sep="") 
  names(x_tra)[In+1] <- "Y"
  names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tst)[In+1] <- "Y"
  if (tt == "train") 
  {
    test <- x_tra
  } 
  else
  {
    test <- x_tst
  }
  fitMulti=kknn(Y~.,x_tra,test)
  yprime=fitMulti$fitted.values
  sum(abs(test$Y-yprime)^2)/length(yprime)
}
knnMSEtrain<-mean(sapply(1:5,run_knn_fold,nombre,"train")) 
knnMSEtest<-mean(sapply(1:5,run_knn_fold,nombre,"test"))
knnMSEtrain
knnMSEtest
```

