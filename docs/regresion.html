<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="joseangeldiazg" />


<title>Regresión</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Programación para Ciencia de Datos con R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="casopractico.html">EDA</a>
</li>
<li>
  <a href="clasificacion.html">Clasificacion</a>
</li>
<li>
  <a href="regresion.html">Regresion</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Regresión</h1>
<h4 class="author"><em>joseangeldiazg</em></h4>
<h4 class="date"><em>4/1/2018</em></h4>

</div>


<div id="regresion" class="section level2">
<h2>6 Regresión</h2>
<p>En este punto del trabajo final de la asignatura aplicaremos técnicas de regresión sobre los datos analizados en el punto 4, sobre el dataset <strong>autompg8</strong>. Concretamente se pide:</p>
<ol style="list-style-type: decimal">
<li><p>Utilizar el algoritmo de regresión lineal simple sobre cada regresor (variable de entrada) para obtener los modelos correspondientes. Si el datasetR asignado incluye más de 5 regresores, seleccione de manera justificada los 5 que considere más relevantes. Una vez obtenidos los modelos, elegir el que considere más adecuado para su conjunto de datos según las medidas de calidad conocidas.</p></li>
<li><p>Utilizar el algoritmo para regresión lineal múltiple. Justificar adecuadamente si el modelo obtenido aporta mejoras respecto al modelo elegido en el paso anterior (en este apartado tenga también en cuenta la consideración de posibles interacciones y no linealidad).</p></li>
<li><p>Aplicar el algoritmo k-NN para regresión.</p></li>
<li><p>Comparar los resultados de los dos algoritmos de regresión múltiple entre sí, y adicionalmente mediante comparativas múltiples con un tercero (el modelo de regresión M5’, cuyos resultados ya están incluidos en las tablas de resultados disponibles).</p></li>
</ol>
</div>
<div id="modelos-lineales-simples" class="section level2">
<h2>6.1 Modelos lineales simples</h2>
<p>Vamos a construir modelos lineales simples para nuestro dataset. Para ello, nos vasaremos en las cinco variables más correlacionadas negativa o positivamente nuestra variable objetivo. Estas son:</p>
<ul>
<li>Cylinders</li>
<li>Displacement</li>
<li>Horse_power</li>
<li>Weight</li>
<li>Model_year</li>
</ul>
<p>Crearemos los modelos e interpretaremos sus resultados.</p>
<pre class="r"><code>fit1=lm(autompg8$Mpg~as.numeric(autompg8$Cylinders))
summary(fit1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ as.numeric(autompg8$Cylinders))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.41419 -0.07953 -0.02191  0.06076  0.48341 
## 
## Coefficients:
##                                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                     0.775447   0.017171   45.16   &lt;2e-16 ***
## as.numeric(autompg8$Cylinders) -0.121894   0.004939  -24.68   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1299 on 389 degrees of freedom
## Multiple R-squared:  0.6103, Adjusted R-squared:  0.6093 
## F-statistic: 609.1 on 1 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~as.numeric(autompg8$Cylinders))
abline(fit1,col=&quot;red&quot;) </code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Vemos que nuestro modelo no ajusta del todo bien, pero ya se obtienen valores de error aceptables que sin lugar a dudas al ser combinados en modelos más complejos ofrecerán buenos resultados.</p>
<p>Seguiremos probando ahora con las demás variables correlacionadas con la variable dependiente.</p>
<pre class="r"><code>fit2=lm(autompg8$Mpg~autompg8$Displacement)
summary(fit2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Displacement)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.34358 -0.08044 -0.01335  0.06260  0.49501 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            0.586141   0.009803   59.79   &lt;2e-16 ***
## autompg8$Displacement -0.618149   0.023104  -26.75   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1234 on 389 degrees of freedom
## Multiple R-squared:  0.6479, Adjusted R-squared:  0.647 
## F-statistic: 715.9 on 1 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~autompg8$Displacement)
abline(fit2,col=&quot;red&quot;) </code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>fit3=lm(autompg8$Mpg~autompg8$Horse_power)
summary(fit3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Horse_power)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.36075 -0.08661 -0.00910  0.07374  0.45030 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           0.62943    0.01202   52.36   &lt;2e-16 ***
## autompg8$Horse_power -0.77216    0.03158  -24.45   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1306 on 389 degrees of freedom
## Multiple R-squared:  0.6058, Adjusted R-squared:  0.6048 
## F-statistic: 597.7 on 1 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~autompg8$Horse_power)
abline(fit3,col=&quot;red&quot;) </code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>fit4=lm(autompg8$Mpg~autompg8$Weight)
summary(fit4)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Weight)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.31828 -0.07319 -0.00930  0.05718  0.43951 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      0.66154    0.01105   59.88   &lt;2e-16 ***
## autompg8$Weight -0.71713    0.02423  -29.60   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1154 on 389 degrees of freedom
## Multiple R-squared:  0.6925, Adjusted R-squared:  0.6917 
## F-statistic:   876 on 1 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~autompg8$Weight)
abline(fit4,col=&quot;red&quot;) </code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>fit5=lm(autompg8$Mpg~as.numeric(autompg8$Model_year))
summary(fit5)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ as.numeric(autompg8$Model_year))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.32034 -0.14526 -0.01095  0.13222  0.48373 
## 
## Coefficients:
##                                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                     0.155461   0.018372   8.462 5.42e-16 ***
## as.numeric(autompg8$Model_year) 0.032801   0.002334  14.055  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1694 on 389 degrees of freedom
## Multiple R-squared:  0.3368, Adjusted R-squared:  0.3351 
## F-statistic: 197.5 on 1 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~as.numeric(autompg8$Model_year))
abline(fit5,col=&quot;red&quot;) </code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Vemos que ajustan bastante bien, pero cabe destacar que si pudieramos obtener un modelo no lineal seguramente conseguiriamos eliminar el error en gran medida, ya que una curva ajustaría mucho mejor con las anteriores variables, de igual modo, basandonos en el valor del R-Squared (ya que solo estamos usando una variable predictora), nuestra candidata sería el modelo <strong>fit4</strong>, donde hemos tenido en cuenta la variable <strong>Weigth</strong> para inferir la variable objetivo <strong>Mpg</strong> y obtenemos valor de R cuadrado de <strong>0,695</strong>.</p>
</div>
<div id="modelos-lineales-multiples-y-no-linealidad." class="section level2">
<h2>6.2 Modelos lineales múltiples y no linealidad.</h2>
<p>Tal y como vimos en el punto anterior, podemos concluir que un modelo no lineal ajuste mejor con nuestras variables, por ello probaremos este con las variables <strong>Weight</strong>, <strong>Horse_power</strong>, <strong>Displacement</strong>.</p>
<pre class="r"><code>fit6&lt;-lm(autompg8$Mpg~autompg8$Weight+I(autompg8$Weight^2))
summary(fit6)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Weight + I(autompg8$Weight^2))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.33558 -0.07194 -0.00963  0.04836  0.42810 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           0.74029    0.01773  41.759  &lt; 2e-16 ***
## autompg8$Weight      -1.22286    0.09398 -13.012  &lt; 2e-16 ***
## I(autompg8$Weight^2)  0.56309    0.10136   5.556 5.15e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1112 on 388 degrees of freedom
## Multiple R-squared:  0.7151, Adjusted R-squared:  0.7137 
## F-statistic:   487 on 2 and 388 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~autompg8$Weight)
points(autompg8$Weight,fitted(fit6),col=&quot;red&quot;,pch=20)</code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>fit7&lt;-lm(autompg8$Mpg~autompg8$Displacement+I(autompg8$Displacement^2))
summary(fit7)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Displacement + I(autompg8$Displacement^2))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.40478 -0.05974 -0.00668  0.05602  0.54561 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                 0.65024    0.01290  50.401  &lt; 2e-16 ***
## autompg8$Displacement      -1.18349    0.08240 -14.362  &lt; 2e-16 ***
## I(autompg8$Displacement^2)  0.67132    0.09438   7.113  5.5e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1162 on 388 degrees of freedom
## Multiple R-squared:  0.6885, Adjusted R-squared:  0.6869 
## F-statistic: 428.9 on 2 and 388 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~autompg8$Displacement)
points(autompg8$Displacement,fitted(fit7),col=&quot;red&quot;,pch=20)</code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>fit8&lt;-lm(autompg8$Mpg~autompg8$Horse_power+I(autompg8$Horse_power^2))
summary(fit8)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Horse_power + I(autompg8$Horse_power^2))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.39110 -0.06898 -0.00225  0.06041  0.42294 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                 0.7727     0.0178   43.41   &lt;2e-16 ***
## autompg8$Horse_power       -1.7278     0.0989  -17.47   &lt;2e-16 ***
## I(autompg8$Horse_power^2)   1.1090     0.1100   10.08   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1164 on 388 degrees of freedom
## Multiple R-squared:  0.6876, Adjusted R-squared:  0.686 
## F-statistic: 426.9 on 2 and 388 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(autompg8$Mpg~autompg8$Horse_power)
points(autompg8$Horse_power,fitted(fit8),col=&quot;red&quot;,pch=20)</code></pre>
<p><img src="regresion_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Vemos como estábamos en lo acertado y ahora, hemos ajustado mucho más nuestro modelo llegando con el modelo basado en la variable <strong>Weight</strong> a tener un R-squared de <strong>0.7151</strong>.</p>
<p>Ahora vamos a generar un modelo basado en regresión lineal múltiple. Para ello, usaremos las 5 variables predictoras que seleccionamos en el proceso de selección de variables. Este modelo, es “secuencial” por lo que iremos añadiendo variables en pequeños pasos para ir comproabando la interacción entre estas.</p>
<pre class="r"><code>fit9&lt;-lm(autompg8$Mpg~autompg8$Weight+autompg8$Displacement)
summary(fit9)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Weight + autompg8$Displacement)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.32982 -0.07775 -0.00997  0.06199  0.43566 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            0.64833    0.01190  54.500  &lt; 2e-16 ***
## autompg8$Weight       -0.54020    0.06677  -8.091 7.67e-15 ***
## autompg8$Displacement -0.16897    0.05950  -2.840  0.00475 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1143 on 388 degrees of freedom
## Multiple R-squared:  0.6987, Adjusted R-squared:  0.6972 
## F-statistic:   450 on 2 and 388 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>fit10&lt;-lm(autompg8$Mpg~autompg8$Weight+autompg8$Displacement+autompg8$Horse_power)
summary(fit10)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Weight + autompg8$Displacement + 
##     autompg8$Horse_power)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.30117 -0.07430 -0.00956  0.05861  0.43209 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            0.66258    0.01254  52.836  &lt; 2e-16 ***
## autompg8$Weight       -0.50285    0.06694  -7.511 4.08e-13 ***
## autompg8$Displacement -0.05800    0.06794  -0.854  0.39379    
## autompg8$Horse_power  -0.20449    0.06280  -3.256  0.00123 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1129 on 387 degrees of freedom
## Multiple R-squared:  0.7068, Adjusted R-squared:  0.7045 
## F-statistic: 310.9 on 3 and 387 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Vemos como acorde al <strong>p-value</strong>, en este modelo, la variable <strong>Displacement</strong> deja de ser relevante para predecir Mpg, por lo que la obviaremos y dejaremos solo las otras dos.</p>
<pre class="r"><code>fit12&lt;-lm(autompg8$Mpg~autompg8$Weight+autompg8$Horse_power)
summary(fit12)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Weight + autompg8$Horse_power)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.29443 -0.07266 -0.00884  0.05859  0.43261 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           0.66785    0.01091  61.202  &lt; 2e-16 ***
## autompg8$Weight      -0.54339    0.04717 -11.519  &lt; 2e-16 ***
## autompg8$Horse_power -0.23138    0.05431  -4.261 2.56e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1129 on 388 degrees of freedom
## Multiple R-squared:  0.7062, Adjusted R-squared:  0.7047 
## F-statistic: 466.4 on 2 and 388 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Al tener varias variables, debemos fijarnos en el valor de <strong>Adjusted R-Squared</strong>, donde vemos como hemos mejorado alguna milésima, y además, ahora Horse_power, recupera relevancia. Seguiremos añadiendo variables a nuestro modelo multiple para ver si mejora.</p>
<pre class="r"><code>fit13&lt;-lm(autompg8$Mpg~autompg8$Weight+autompg8$Horse_power+autompg8$Model_year+autompg8$Origin)
summary(fit13)</code></pre>
<pre><code>## 
## Call:
## lm(formula = autompg8$Mpg ~ autompg8$Weight + autompg8$Horse_power + 
##     autompg8$Model_year + autompg8$Origin)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.27490 -0.05181 -0.00070  0.04539  0.33524 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            0.499557   0.021853  22.859  &lt; 2e-16 ***
## autompg8$Weight       -0.475452   0.040993 -11.598  &lt; 2e-16 ***
## autompg8$Horse_power  -0.079169   0.046506  -1.702  0.08952 .  
## autompg8$Model_year71  0.024259   0.023072   1.051  0.29372    
## autompg8$Model_year72 -0.009124   0.022458  -0.406  0.68477    
## autompg8$Model_year73 -0.018735   0.020511  -0.913  0.36162    
## autompg8$Model_year74  0.033558   0.024010   1.398  0.16304    
## autompg8$Model_year75  0.017086   0.023543   0.726  0.46845    
## autompg8$Model_year76  0.037687   0.022587   1.669  0.09605 .  
## autompg8$Model_year77  0.075822   0.023007   3.296  0.00108 ** 
## autompg8$Model_year78  0.071831   0.021919   3.277  0.00115 ** 
## autompg8$Model_year79  0.135817   0.023260   5.839 1.14e-08 ***
## autompg8$Model_year80  0.244007   0.024549   9.940  &lt; 2e-16 ***
## autompg8$Model_year81  0.173832   0.024212   7.179 3.80e-12 ***
## autompg8$Model_year82  0.220484   0.023696   9.305  &lt; 2e-16 ***
## autompg8$Origin2       0.051296   0.012936   3.965 8.79e-05 ***
## autompg8$Origin3       0.054316   0.013226   4.107 4.93e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.08162 on 374 degrees of freedom
## Multiple R-squared:  0.852,  Adjusted R-squared:  0.8456 
## F-statistic: 134.5 on 16 and 374 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Parece que al al añadir nuestras variables <strong>Model_year</strong> y <strong>Origin</strong>, el modelo mejora bastante.Por último, vamos a probar que pasaría si usaramos todas las variables del modelo y que pasaría si al modelo fit13, aplicaramos las transformaciones de no linealidad vistas al inicio de esta sección.</p>
<pre class="r"><code>fit14&lt;-lm(Mpg~.,data=autompg8)
summary(fit14)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Mpg ~ ., data = autompg8)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.210387 -0.043723 -0.001234  0.038328  0.308375 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.333616   0.049249   6.774 4.98e-11 ***
## Cylinders4    0.184485   0.040889   4.512 8.66e-06 ***
## Cylinders5    0.176539   0.062195   2.838 0.004784 ** 
## Cylinders6    0.114221   0.045391   2.516 0.012281 *  
## Cylinders8    0.169692   0.052390   3.239 0.001308 ** 
## Displacement  0.118497   0.069894   1.695 0.090849 .  
## Horse_power  -0.187774   0.064058  -2.931 0.003586 ** 
## Weight       -0.486319   0.058579  -8.302 1.97e-15 ***
## Acceleration  0.004389   0.039012   0.112 0.910494    
## Model_year71  0.024415   0.021704   1.125 0.261365    
## Model_year72 -0.013140   0.021391  -0.614 0.539393    
## Model_year73 -0.014654   0.019198  -0.763 0.445763    
## Model_year74  0.033105   0.022745   1.455 0.146387    
## Model_year75  0.023308   0.022285   1.046 0.296290    
## Model_year76  0.039888   0.021339   1.869 0.062384 .  
## Model_year77  0.079772   0.021818   3.656 0.000293 ***
## Model_year78  0.079116   0.020735   3.816 0.000159 ***
## Model_year79  0.130253   0.021949   5.934 6.81e-09 ***
## Model_year80  0.241063   0.023290  10.351  &lt; 2e-16 ***
## Model_year81  0.171932   0.022984   7.480 5.50e-13 ***
## Model_year82  0.210392   0.022742   9.251  &lt; 2e-16 ***
## Origin2       0.044394   0.013761   3.226 0.001367 ** 
## Origin3       0.060206   0.013256   4.542 7.58e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.07577 on 368 degrees of freedom
## Multiple R-squared:  0.8745, Adjusted R-squared:  0.867 
## F-statistic: 116.5 on 22 and 368 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Parece que obtenemos grandes resultados y una mejora muy clara respecto a usar solo algunas variables, vemos como las variables que consideramos importantes siguen siendolo. Comprobaremos ahora que pasaría si aplicaramos las transformaciones.</p>
<pre class="r"><code>fit15&lt;-lm(Mpg~Cylinders+Displacement+I(Displacement^2)+Horse_power+I(Horse_power^2)+Weight+I(Weight^2)+Model_year,data=autompg8)
summary(fit15)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Mpg ~ Cylinders + Displacement + I(Displacement^2) + 
##     Horse_power + I(Horse_power^2) + Weight + I(Weight^2) + Model_year, 
##     data = autompg8)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.25707 -0.03977  0.00208  0.03716  0.30667 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        0.463939   0.044012  10.541  &lt; 2e-16 ***
## Cylinders4         0.200943   0.038201   5.260 2.45e-07 ***
## Cylinders5         0.242446   0.056179   4.316 2.05e-05 ***
## Cylinders6         0.224415   0.046518   4.824 2.06e-06 ***
## Cylinders8         0.264080   0.053140   4.970 1.03e-06 ***
## Displacement      -0.529245   0.148323  -3.568 0.000407 ***
## I(Displacement^2)  0.456616   0.131779   3.465 0.000593 ***
## Horse_power       -0.334531   0.099532  -3.361 0.000858 ***
## I(Horse_power^2)   0.140365   0.104199   1.347 0.178782    
## Weight            -0.698076   0.124117  -5.624 3.69e-08 ***
## I(Weight^2)        0.360559   0.108160   3.334 0.000944 ***
## Model_year71       0.009831   0.020308   0.484 0.628608    
## Model_year72      -0.013215   0.019523  -0.677 0.498896    
## Model_year73      -0.023850   0.017618  -1.354 0.176643    
## Model_year74       0.018381   0.020687   0.889 0.374844    
## Model_year75       0.027452   0.020072   1.368 0.172244    
## Model_year76       0.037898   0.019217   1.972 0.049343 *  
## Model_year77       0.073414   0.019740   3.719 0.000231 ***
## Model_year78       0.085791   0.018636   4.603 5.73e-06 ***
## Model_year79       0.132805   0.019747   6.725 6.71e-11 ***
## Model_year80       0.245145   0.020632  11.882  &lt; 2e-16 ***
## Model_year81       0.165871   0.020206   8.209 3.80e-15 ***
## Model_year82       0.211935   0.020075  10.557  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.06823 on 368 degrees of freedom
## Multiple R-squared:  0.8982, Adjusted R-squared:  0.8921 
## F-statistic: 147.6 on 22 and 368 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Obtenemos un valor de Adjusted R-Squared muy bueno del <strong>0,8921</strong>, que está aún lejos de valores de confianza aceptables pero que representa una gran mejora desde que creamos los primeros modelos simples.</p>
</div>
<div id="k-nn-para-regresion." class="section level2">
<h2>6.3 K-NN para regresión.</h2>
<p>En este punto utilizaremos validación cruzada con el algoritmo Knn sobre el dataset. Para ello, haremos uso de las particiones facilitadas en el dataset de KEEL.</p>
<pre class="r"><code>require(kknn)
setwd(&quot;/Users/joseadiazg/Desktop/MASTER CIENCIA DE DATOS/introduccion-ciencia-datos/datasets/DatasetsRegresion/autoMPG8/&quot;)

nombre &lt;- &quot;autoMPG8&quot;

run_knn_fold &lt;- function(i, x, tt = &quot;test&quot;) 
{
  file &lt;- paste(x, &quot;-5-&quot;, i, &quot;tra.dat&quot;, sep=&quot;&quot;)
  x_tra &lt;- read.csv(file, comment.char=&quot;@&quot;) 
  file &lt;- paste(x, &quot;-5-&quot;, i, &quot;tst.dat&quot;, sep=&quot;&quot;)
  x_tst &lt;- read.csv(file, comment.char=&quot;@&quot;)
  In &lt;- length(names(x_tra)) - 1 
  names(x_tra)[1:In] &lt;- paste (&quot;X&quot;, 1:In, sep=&quot;&quot;) 
  names(x_tra)[In+1] &lt;- &quot;Y&quot;
  names(x_tst)[1:In] &lt;- paste (&quot;X&quot;, 1:In, sep=&quot;&quot;)
  names(x_tst)[In+1] &lt;- &quot;Y&quot;
  if (tt == &quot;train&quot;) 
  {
    test &lt;- x_tra
  } 
  else
  {
    test &lt;- x_tst
  }
  fitMulti=kknn(Y~.,x_tra,test)
  yprime=fitMulti$fitted.values
  sum(abs(test$Y-yprime)^2)/length(yprime)
}
knnMSEtrain&lt;-mean(sapply(1:5,run_knn_fold,nombre,&quot;train&quot;)) 
knnMSEtest&lt;-mean(sapply(1:5,run_knn_fold,nombre,&quot;test&quot;))
knnMSEtrain</code></pre>
<pre><code>## [1] 3.551719</code></pre>
<pre class="r"><code>knnMSEtest</code></pre>
<pre><code>## [1] 8.106899</code></pre>
<p>Vemos que los resultados son bastante buenos e incluso mejores que los obtenidos por nuestro modelo de regresión lineal. Esto constata la robusted de un algoritmo en aparicia sencillo como el K-NN. Cabe destacar tambien la diferencia entre test y train, pese a utilizar validación cruzada el algoritmo sobre ajusta en cierta medida.</p>
</div>
<div id="comparacion-de-modelos." class="section level2">
<h2>Comparación de modelos.</h2>
<p>En este punto, compararemos los resultados de la salida del algoritmo Knn con validación cruzada y el modelo lineal múltiple, sobre el que aplicaremos también validación cruzada. Con estos resultados, y los obtenidos para otra serie de dataset, aplicaremos comparaciones usando los test de <strong>Wilcoxon, Friedman</strong> y <strong>Holm</strong>.</p>
<pre class="r"><code>setwd(&quot;/Users/joseadiazg/Desktop/MASTER CIENCIA DE DATOS/introduccion-ciencia-datos/datasets/DatasetsRegresion/autoMPG8/&quot;)
nombre &lt;- &quot;autoMPG8&quot;
run_lm_fold &lt;- function(i, x, tt = &quot;test&quot;) 
{
  file &lt;- paste(x, &quot;-5-&quot;, i, &quot;tra.dat&quot;, sep=&quot;&quot;)
  x_tra &lt;- read.csv(file, comment.char=&quot;@&quot;) 
  file &lt;- paste(x, &quot;-5-&quot;, i, &quot;tst.dat&quot;, sep=&quot;&quot;)
  x_tst &lt;- read.csv(file, comment.char=&quot;@&quot;)
  In &lt;- length(names(x_tra)) - 1 
  names(x_tra)[1:In] &lt;- paste (&quot;X&quot;, 1:In, sep=&quot;&quot;) 
  names(x_tra)[In+1] &lt;- &quot;Y&quot;
  names(x_tst)[1:In] &lt;- paste (&quot;X&quot;, 1:In, sep=&quot;&quot;)
  names(x_tst)[In+1] &lt;- &quot;Y&quot;
  if (tt == &quot;train&quot;) 
  {
    test &lt;- x_tra
  } 
  else
  {
    test &lt;- x_tst
  }
  fitMulti=lm(Y~.,x_tra)
  yprime=predict(fitMulti,test)
  sum(abs(test$Y-yprime)^2)/length(yprime)
}
lmMSEtrain&lt;-mean(sapply(1:5,run_lm_fold,nombre,&quot;train&quot;)) 
lmMSEtest&lt;-mean(sapply(1:5,run_lm_fold,nombre,&quot;test&quot;))
lmMSEtrain</code></pre>
<pre><code>## [1] 10.78899</code></pre>
<pre class="r"><code>lmMSEtest</code></pre>
<pre><code>## [1] 11.40106</code></pre>
<p>Con estos resultados, sustituiremos los valores en las tablas de resultados de los demás conjuntos de datos y compararemos usando los tests. Primero compararemos usando Wilconxon, el algoritmo Knn (referencia por ofrecer mejores resultados) y Regresión.</p>
<p>Aunque los datos que más nos interesan son los de <strong>test</strong>, cargaremos y aplicaremos los test también en <strong>training</strong>, ya que es interesante su estudio de cara a obtener más informacion de fenomenos como el sobreajuste por ejemplo. Por tanto, primero debemos cargar los datos para train y para test.</p>
<pre class="r"><code>resultadosTrain &lt;- read.table(&quot;./comparaciones/regr_train_alumnos.csv&quot;)
resultadosTest &lt;- read.table(&quot;./comparaciones/regr_test_alumnos.csv&quot;)
difsTrain &lt;- (resultadosTrain[,2] - resultadosTrain[,1]) / resultadosTrain[,2]
difsTest &lt;- (resultadosTest[,2] - resultadosTest[,1]) / resultadosTest[,2]

#Datos para train

wilc_knn_ln_train &lt;- cbind(ifelse (difsTrain&lt;0, abs(difsTrain)+0.1, 0+0.1), ifelse (difsTrain&gt;0, abs(difsTrain)+0.1, 0+0.1)) 

colnames(wilc_knn_ln_train) &lt;- c(colnames(resultadosTrain)[2], colnames(resultadosTrain)[1])
head(wilc_knn_ln_train)</code></pre>
<pre><code>##      out_train_kknn out_train_lm
## [1,]       1.271171          0.1
## [2,]      26.084127          0.1
## [3,]       2.298300          0.1
## [4,]       2.137681          0.1
## [5,]       1.317643          0.1
## [6,]       2.191989          0.1</code></pre>
<pre class="r"><code>#Datos para test

wilc_knn_ln_test &lt;- cbind(ifelse (difsTest&lt;0, abs(difsTest)+0.1, 0+0.1), ifelse (difsTest&gt;0, abs(difsTest)+0.1, 0+0.1)) 

colnames(wilc_knn_ln_test) &lt;- c(colnames(resultadosTest)[2], colnames(resultadosTest)[1])
head(wilc_knn_ln_test)</code></pre>
<pre><code>##      out_test_kknn out_test_lm
## [1,]     0.1000000   0.1833333
## [2,]     0.1000000   1.0858333
## [3,]     0.6012920   0.1000000
## [4,]     0.5063405   0.1000000
## [5,]     0.1000000   0.1519985
## [6,]     0.3596135   0.1000000</code></pre>
<p>Ahora podemos aplicar el test de Wilconxon. Para ello procedemos de la siguiente manera:</p>
<pre class="r"><code>KKNNvsLNtra &lt;- wilcox.test(wilc_knn_ln_train[,1], wilc_knn_ln_train[,2], alternative = &quot;two.sided&quot;, paired=TRUE) 
KKNNvsLNtst &lt;- wilcox.test(wilc_knn_ln_test[,1], wilc_knn_ln_test[,2], alternative = &quot;two.sided&quot;, paired=TRUE) 

RmasTest &lt;- KKNNvsLNtst$statistic
pvalueTest &lt;- KKNNvsLNtst$p.value

RmasTra &lt;- KKNNvsLNtra$statistic
pvalueTra &lt;- KKNNvsLNtra$p.value

KKNNvsLNtra &lt;- wilcox.test(wilc_knn_ln_train[,2], wilc_knn_ln_train[,1], alternative = &quot;two.sided&quot;, paired=TRUE) 
KKNNvsLNtst &lt;- wilcox.test(wilc_knn_ln_test[,2], wilc_knn_ln_test[,1], alternative = &quot;two.sided&quot;, paired=TRUE) 

RmenosTest &lt;- KKNNvsLNtst$statistic
RmenosTra &lt;-  KKNNvsLNtra$statistic

print(&quot;Resultados en Test:&quot;)</code></pre>
<pre><code>## [1] &quot;Resultados en Test:&quot;</code></pre>
<pre class="r"><code>RmasTest</code></pre>
<pre><code>##  V 
## 94</code></pre>
<pre class="r"><code>RmenosTest</code></pre>
<pre><code>##  V 
## 77</code></pre>
<pre class="r"><code>pvalueTest</code></pre>
<pre><code>## [1] 0.7337265</code></pre>
<pre class="r"><code>print(&quot;Resultados en Training:&quot;)</code></pre>
<pre><code>## [1] &quot;Resultados en Training:&quot;</code></pre>
<pre class="r"><code>RmasTra</code></pre>
<pre><code>##   V 
## 168</code></pre>
<pre class="r"><code>RmenosTra</code></pre>
<pre><code>## V 
## 3</code></pre>
<pre class="r"><code>pvalueTra</code></pre>
<pre><code>## [1] 3.814697e-05</code></pre>
<p>Los resultados son discordantes. En test, no podríamos asegurar que existieran diferencias significativas entre los algoritmos, más bien, podriamos decir casi con total seguridad que son iguales, ya que el pvalue es muy alto. Por otro lado, en training ocurre lo contrario tenemos un p-value tan bajo que nos dice que los algoritmos son diferentes casi al 100% de seguridad, esto puede ser debido a que tenemos mucho sobreajuste con uno de los algoritmos que nos ofrece resultados muy buenos en training.</p>
<p>Vamos a comprar ahora los tres algoritmos usando el test de <strong>Friedman</strong>.</p>
<pre class="r"><code>test_friedmanTra &lt;- friedman.test(as.matrix(resultadosTrain[,1:3]))
test_friedmanTst &lt;- friedman.test(as.matrix(resultadosTest[,1:3]))
test_friedmanTra</code></pre>
<pre><code>## 
##  Friedman rank sum test
## 
## data:  as.matrix(resultadosTrain[, 1:3])
## Friedman chi-squared = 20.333, df = 2, p-value = 3.843e-05</code></pre>
<pre class="r"><code>test_friedmanTst</code></pre>
<pre><code>## 
##  Friedman rank sum test
## 
## data:  as.matrix(resultadosTest[, 1:3])
## Friedman chi-squared = 5.3333, df = 2, p-value = 0.06948</code></pre>
<p>Acorde al test de Friedman, y los valores de p-value observados cercanos a 0 tanto en training como en test, podemos concluir que existen diferencias significativas, al menos, entre dos algoritmos de los tres estudiados. En base a esta premisa, usaremos el test de <strong>Holm</strong> para discernir que está ocurriendo con estos algoritmos.</p>
<pre class="r"><code>tam &lt;- dim(resultadosTest[,1:3])
groups &lt;- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(resultadosTest[,1:3]), groups, p.adjust = &quot;holm&quot;, paired = TRUE)</code></pre>
<pre><code>## 
##  Pairwise comparisons using Wilcoxon signed rank test 
## 
## data:  as.matrix(resultadosTest[, 1:3]) and groups 
## 
##   1    2   
## 2 0.97 -   
## 3 0.27 0.27
## 
## P value adjustment method: holm</code></pre>
<pre class="r"><code>tam &lt;- dim(resultadosTrain[,1:3])
groups &lt;- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(resultadosTrain[,1:3]), groups, p.adjust = &quot;holm&quot;, paired = TRUE)</code></pre>
<pre><code>## 
##  Pairwise comparisons using Wilcoxon signed rank test 
## 
## data:  as.matrix(resultadosTrain[, 1:3]) and groups 
## 
##   1      2     
## 2 0.0067 -     
## 3 0.0039 0.0067
## 
## P value adjustment method: holm</code></pre>
<p>En base a los datos de test, parece que el algorimo M5, es ciertamente mejor que los demás, aunque los resultados no son concuyentes. Por otro lado, en base a los resultados de training, podemos comprar que el algoritmo M5 es mejor que el LM y KNN con pvalues de 0.0039, y 0.0067 frente a estos y que a su mismo tiempo, el algoritmo KNN está por delante del LM, con un valor de p-value de 0.0067.</p>
</div>
<div id="resumen-y-conclusiones-finales-de-los-modelos-de-regresion." class="section level2">
<h2>6.5 Resumen y conclusiones finales de los modelos de regresión.</h2>
<p>El estudio del dataset autompg8 para regresión, nos ha ayudado a comprender la potencia de los métodos de regresión, tanto para predecir valores en nuestras variables objetivos como para ayuda en los procesos de análisis exploratorio de datos, donde los algoritmos basados en regresiones lineales simples y combinadas nos ayudan a comprender aún mejor las distribuciones de las variables y la posibles interacciones entre las mismas.</p>
<p>Cabe destacar, la potencia del método en su uso por ejemplo para predecir valores perdidos en una variable en la cual hubiera presencia de estos y algún tipo de correlación con alguna de las otras variables presentes en el problema.</p>
<p>Por último, pese a que no hemos ahondado mucho en las interacciones y la no linealidad, queda constatado como estudiar los datos y comprobar que tipo de función se adapta mejor a los mismos, nos ayudará a obtener mejores modelos, en este caso, con una simple función cuadrática hemos conseguido valores de R cuadrado de prácticamente el 90% de acierto.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
