---
title: "Exploratory Data Analysis in R"
author: joseangeldiazg
date: November 25 2017
output: html_document
---

# Ejemplo 1, hip dataset


Descargate el  dataset hip con el siguiente commando 

```{r}
hip  <-read.table("http://astrostatistics.psu.edu/datasets/HIP_star.dat", header=T,fill=T)
```

* Una vez descargado comprueba la dimensión y los nombres de las columnas del dataset. ¿Qué dimensión tiene? ¿qué datos alberga?

```{r}
str(hip)
```

Con el comando **str** vemos la información solicitada concretamente 2719 observaciones con 9 características, además vemos el tipo de dato de cada característica. 


* Muestra por pantalla la columna de la variable RA


```{r}
hip[,3]
```


* Calcula las tendencias centrales de todos los datos del dataset (mean, media) utilizando la function apply

```{r}
apply(hip,2,mean, na.rm=T)
apply(hip,2,median, na.rm=T)
```

* Haz lo mismo para las medidas de dispersión mínimo y máximo. 

```{r}
apply(hip,2,min, na.rm=T)
apply(hip,2,max, na.rm=T)
```

* ¿Sería posible hacerlo con un único comando? ¿Que hace la función range()

Si que sería posible, para ello usaremos la función range que nos da el rango de valores comprendido para una determinada característica del dataset.  

```{r}
apply(hip,2,range, na.rm=T)
```


* Sin embargo las medidas más populares de dispersión son la varianza (var()), su desviación standard (sd()) y la desviación absoluta de la mediana o MAD. Calcula estas medidas para los valores de RA.

```{r}
apply(hip,2,var, na.rm=T)
apply(hip,2,sd, na.rm=T)
apply(hip,2,mad, na.rm=T)
```

* Imagina que quieres calcular dos de estos valores de una sola vez. ¿Te serviría este código?

```{r}
f = function(x) c(median(x), mad(x))  
f(hip[,1])
```

Si que valdría y calcularía para la columna 1 la mediana y la desviación absoluta de la mediana. 

* ¿Cuál sería el resultado de aplicar apply(hip,2,f)?

El resultado de esta función sería aplicar para cada columna la mediana y la desviación absoluta de la mediana. 

```{r}
apply(hip,2,f)
```


Vamos a medir la dispersión de la muestra utilizando el concepto de cuartiles. El percentil 90 es aquel dato que excede en un 10% a todos los demás datos. El cuartil (quantile) es el mismo concento, solo que habla de proporciones en vez de porcentajes. De forma que el percentil 90 es lo mismo que el cuartil 0.90. La mediana “median” de un dataset es el valor más central, en otras palabras exactamente la mitad del dataset excede la mediana. 


* Calcula el cuartil .10 y .50 para la columna RA del dataset hip. Sugerencia: quantile()

```{r}
quantile(hip$RA, probs = c(0.1, 0.5))
```


* Los cuantiles 0.25 y 0.75 se conocen como el  first quartile y el third quartile, respectivamente. Calcula los cuatro cuartiles para RA con un único comando.


```{r}
quantile(hip$RA, probs=c(0.25,0.5,0.75))
```



* Otra medida de dispersión es la diferencia entre el primer y el tercer cuartil conocida como rango intercuartil (IQR) Inter Quantile Range. ¿Obtienes ese valor con la función summary()?

El valor como tal no es ofrecido por la función summary, pero si que obtenemos los valores necesarios para calcularlo. Si queremos tenerlo directamente debemos usar la funcion **IQR.**


```{r}
summary(hip$RA, na.rm=T)
IQR(hip$RA)
```


Hasta ahora has ignorado la presencia de  valores perdidos NA. La función any() devuelve TRUE si se encuentra al menos un TRUE en el vector que damos como argumento. Su combinación con is.na es muy útil.

* ¿Qué obtienes cuando ejecutas el siguiente comando? ¿Cómo lo interpretas?

El siguiente comando, lo que hace es crear una función hasNA que nos dice si algun elemento de los datos que se le pasan como argumento es un *missing value*. Con la funcion apply, lo que hacemos es usarlo para cada columna del dataset hip y este nos devuelve que en la variable B.V, tenemos valores perdidos. 

```{r}
hasNA = function(x) any(is.na(x)) 
apply(hip,2,hasNA)   
```


* Normalmente querríamos poder usar las funciones  sobre el resto de datos que no son NA: Para ello podemos utilizar la función na.omit. ¿Que ocurre cuando lo hacemos?. Usando apply calcula la media para hip y hip1. Intenta calcular la media de forma que solo cambie la de B.V cuando ignores los valores NA.

* Obten una idea aproximada de tus datos mediante la creación de un boxplot del hip dataset


```{r}
boxplot(hip, main="HIP BOX PLOT", ylab="Value", xlab="Variable")
```

Vemos que el gráfico no es muy revelador esto es porque tenemos variables de rangos muy distintos, podemos normalizarlas para ver algo mejor la dispersion de los datos. De todas formas este gráfico ya nos aportaria información como que la variable HIP está muy por encima de  los valores de las demás que se encuentran en rangos similares en función a esta y que tenemos presencia de bastantes outliers en pmRA y pmDE. Vamos a normalizar para ver si el resultado mejora:


```{r}
library(scales)
hip_norm<-hip

hip_norm$HIP <- rescale(hip$HIP)
hip_norm$Vmag <- rescale(hip$Vmag)
hip_norm$RA <- rescale(hip$RA)
hip_norm$DE <-rescale(hip$DE)
hip_norm$Plx<-rescale(hip$Plx)
hip_norm$pmRA<-rescale(hip$pmRA)
hip_norm$pmDE<-rescale(hip$pmDE)
hip_norm$e_Plx<-rescale(hip$e_Plx)


boxplot(hip_norm, main="HIP BOX PLOT NORMALIZADO", ylab="Value", xlab="Variable")
```



* Crea un scatterplot que te compare los valores de RA y DE. Representa los puntos con el símbolo ‘.’ Y que estos puntos sean de color rojo si DE excede de 0. Sugerencia ifelse()

```{r}
ggplot(hip, aes(x=hip$RA, y=hip$DE))+ geom_point(size=2,color=ifelse(hip$DE>0,"red","blue"),shape=1)
```

* Haz un scatterplot de RA y pmRA. ¿Ves algún patrón?

```{r}
ggplot(hip, aes(x=hip$RA, y=hip$pmRA))+ geom_point(size=2,shape=2)+geom_smooth(method=lm,color="darkred")
```

Aunque parece que a valores entre 100 y 150 de RA obtenemos valores más pequeños de pmRA la distribución de estos datos es bastante compleja y esto que apreciamos no es suficientemente concluyente para poder afirmar que exiten relaciones entre ambas variables. 


* En vez de crear los plots por separado para cada par de columnas, hazlos con un solo comando con el scatterplot matrix.

Para esto podemos usar pairs, pero si usamos el comando ggpairs nos ofrecerá mas informacion como correlaciones entre vairables e incluso distribuciones de las mismas. 

```{r}
install.packages("GGAlly")
library(GGally)
ggpairs(hip[1:8])
```

* Para poder acceder a las variables por su nombre usa attach(hip).Vamos a seleccionar las estrellas Hyadas del dataset aplicando los siguientes filtros:


1. RA in the range (50,100) 
2. DE in the range (0,25) 
3. pmRA in the range (90,130) 
4. pmDE in the range (-60,-10) 
5. e_Plx <5 
6. Vmag >4 OR B.V <0.2 

Crea un nuevo dataset con la aplicación de estos filtro. El Nuevo dataset se llama hyades. 


```{r}
hip <- hip[complete.cases(hip), ]
hyades<-hip[hip$RA > 50 & hip$RA < 100 &
    hip$DE>0 & hip$DE<25 &
    hip$pmRA>90 & hip$pmRA<130 &
    hip$pmDE> -60 & hip$pmDE< -10 &
    hip$e_Plx < 5 &
    (hip$Vmag>4|hip$B.V<0.2),]

hyades
```


* ¿Que dimensiones tiene el dataset creado? Grafica un scatterplot de Vmag vs B.V

Tiene 88 observaciones con 9 variables cada una. 

```{r}
str(hyades)
ggplot(hyades, aes(x=hyades$Vmag, y=hyades$B.V))+ geom_point(size=1,shape=1)
```

Analizando el gráfico podemos ver que la relación de las variables es totalmente lineal, lo que podria ayudarnos por ejemplo a poder predecir mediente regresión posibles valores perdidos en una de ambas. Tambien podremos descartar una de ellas en función de otra en nuestros modelos ya que ambas pueden aportar información muy similar al estár tan correlacionadas. 


# Ejemplo 2, iris dataset


Vamos a utilizar el ejemplo del dataset iris que está incluido en la distribución de R. Este dataset fue creado por **Douglas Fisher**.  Consta de tres clases y tipos de 3 clases de tipos de flores:

1. Setosa_
2. Virginica
3. Versicolor
  
Cada una de ellas con cuatro atributos:

1. sepal width
2. sepal length
3. petal width
4. petal length


* Inspecciona las primeras filas del dataset y calcula el summary() del mismo con cada atributo del dataset.

Esto nos ayuda a tener una idea inicial de como son los datos, en este caso están perfectamente equilibradas las clases, los rangos de valores son mas o menos similares y el IRQ es similar. 

```{r}
iris.data<-iris
head(iris.data)
summary(iris.data)
str(iris.data)
```


* Crea un histograma de petal.width , teniendo en cuenta que el número de bins es variable fija este a 9. Añádele color y nombres al eje x "Petal Width"y al gráfico dale el nombre de  "Histogram of Petal Width". 

```{r}
library(ggplot2)
ggplot(data=iris.data, aes(iris.data$Petal.Width)) + geom_histogram(binwidth = 0.3) +labs(title="Histogram of Petal Width",x ="Petal Width", y = "Frecuency")
```

* Crea un histograma para cada variable.


```{r}
ggplot(data=iris.data, aes(iris.data$Sepal.Length)) + geom_histogram(binwidth = 0.5) +labs(title="Histogram of Sepal.Length",x ="Sepal.Length", y = "Frecuency")

ggplot(data=iris.data, aes(iris.data$Sepal.Width)) + geom_histogram(binwidth = 0.5) +labs(title="Histogram of Sepal.Width",x ="Sepal.Width", y = "Frecuency")

ggplot(data=iris.data, aes(iris.data$Petal.Length)) + geom_histogram(binwidth = 0.5) +labs(title="Histogram of Petal.Length",x ="Petal.Length", y = "Frecuency")
```


* Crea los cuartiles del dataset

```{r}
summary(iris.data, na.rm=T)
```

* Representa en un boxplot la variable de ancho de hoja dependiendo del tipo de hoja que tengan.

```{r}
boxplot(iris.data$Sepal.Width~iris.data$Species, main="Ancho de Hoja por Especie", ylab="Ancho de Hoja", xlab="Especie")
```

Este gráfico no podemos ver una tendencia clara, más haya de que encontramos los cuartiles bien distribuidos y salvo un caso la existencia de outliers es nula.

* Crea los boxplot de la longitud del pétalo en función de la especie de Iris.

```{r}
boxplot(iris.data$Petal.Length~iris.data$Species, main="Longitud Petalo de Hoja por Especie", ylab="Longitud de Petalo", xlab="Especie")
```

Este gráfico ya nos ofrece mucha información, vemos una tendencia entre los datos de setosa a virginica, en función del Sepal Lenght muy clara, ya que cuanto mayor es cambia la especie. También vemos un outlier en la especie versicolor y setosa. 

* Compara con scatter plots las variables entre sí.

Vamos a volver a usar ggpairs, que nos ofrece mucha más información.

```{r}
ggpairs(iris.data)
```


### SWISS dataset

El conjunto de datos “swiss” contiene una medida estandarizada de fecundidad y varios indicadores socioeconómicos para cada una de las 47 provincias francófonas de Suiza. 

```{r}
head(swiss)
```


* ¿Qué diagrama dibujaría para mostrar la distribución de todos los valores? ¿Qué conclusiones sacarías?


Para obtener la distribución de todos los valores realizaría un Boxplot. En base al diagrama, podemos concluir que hay un valor que claramente es un %, **Catholic**, este ademas ofrece una dispersión entre los que están por encima de la mediana muy alta, frente a los que están por debajo de la misma. 

Por otro lado, tenemos bastantes outliers en **Education**.


```{r}
boxplot(swiss, main="Boxplot Swiss", xlab="Variables", ylab="Valor")
```


* Dibuje gráficos para cada variable. ¿Qué puede concluir de las distribuciones con respecto a su forma y posibles valores atípicos? 

* Dibuja un diagrama de dispersión de Fertilidad frente a % Catholic. ¿Qué tipo de áreas tienen las tasas de fertilidad más bajas? 

```{r}
ggplot(swiss, aes(x=swiss$Catholic, y=swiss$Fertility))+
  geom_point(size=2,shape=5)
```

Las áreas con menor fertilidad son aquellas que tienen un % de católicos entre el 50% y 60%.


* ¿Qué tipo de relación existe entre las variables Educación y Agricultura?

```{r}
ggplot(swiss, aes(x=swiss$Education, y=swiss$Agriculture))+
  geom_point(size=2,shape=1)+
  geom_smooth(method=loess,color="darkred")
```


Aunque la relación no es muy clara, una vez visto el gráfico podemos ver que a menores valores de educación, mayores de educación por lo que el gráfico se asemeja a una función exponencial con una correlación negativa bastante fuerte. 


### Aceites de Oliva


El conjunto de datos de aceites de oliva es bien conocido y se puede encontrar en varios paquetes, por ejemplo, como **olives** en extracat.La fuente original de los datos es el artículo [Forina et al., 1983]. 

Vamos a obtener el dataset:

```{r}
install.packages("extracat")
library(extracat)
head(olives)
```
 
1. Dibuje un scatterplot  de las ocho variables continuas. ¿Cuáles de los ácidos grasos están fuertemente asociados positivamente y cuáles fuertemente asociados negativamente? 

```{r}
ggpairs(olives[3:10])
```
Nuevamente con ggpairs obtenemos la información que deseamos, ya que nos ofrece las correlaciones negaticas y positicas entre cada uno de los gráficos. 

* ¿Hay valores atípicos u otras características que valga la pena mencionar?

```{r}
boxplot(olives[3:10])
```


Aunque deberíamos usar normalización para ver los datos representados en una misma escala podemos concluir que hay ciertos valores atípicos o outliers, en **stearic**, **linolenic** sobre todo. 

### HSAUR2.

El conjunto de datos se llama Lanza del paquete HSAUR2, por ello, lo primero será obtener los datos. 

```{r}
install.packages("HSAUR2")
library("HSAUR2")
Lanza
```
*Se informan los datos de cuatro estudios. Dibuje un diagrama para mostrar si los cuatro estudios son igualmente grandes. 

Para obtener la información sobre el número de elementos de una determinada variable el mejor gráfico es un gráfico de barras.

```{r}
estudy.freq <- table(Lanza$study) 
barplot(estudy.freq)
```

Vemos que los estudios de tipo IV, están en clara minoría, por lo que podremos tener sesgos en estas clases a la hora de clasificar a los que tendremos que prestar mucha atención. 

* El resultado se mide por la clasificación de la variable con puntuaciones de 1 (mejor) a 5 (peor). ¿Cómo describirías la distribución?


Pues hay una clara diferencia entre las clasificadas como 1 y las demás, que con ciertos matices, están bastante bien distribuidas. 

```{r}
class.freq <- table(Lanza$classification) 
barplot(class.freq)
```


### Cáncer de mama

El paquete vcdExtra incluye datos de un viejo estudio de cáncer de mama sobre la supervivencia o muerte de 474 pacientes. 

```{r}
install.packages("vcdExtra")
library("vcdExtra")
cancer.dataframe<-as.data.frame(Cancer)
```

* Convierta los datos en un data frame y dibuje gráficos para comparar las tasas de supervivencia, primero, por grado de malignidad y, en segundo lugar, por centro de diagnóstico. 


Para este caso lo mejor es un gráfico de mosaico.

```{r}
library(vcd)
mosaic(Survival ~ Grade, data = cancer.dataframe, shade=TRUE)
mosaic(Survival ~ Center, data = cancer.dataframe, shade=TRUE)
```

En cuanto a centros las tasas son muy parecidas en cambio, cuando vemos si es benigno o maligno si que, como la propia logica nos diría, al ser maligno los supervivientes son menos. 

* ¿Qué diagrama dibujaría para comparar las tasas de supervivencia tanto por grado de malignidad como por centro de diagnóstico? ¿Importa el orden de las variables explicativas?

Para meter todo dentro de un gráfico volvería a usar el gráfico de mosaico. 

```{r}
mosaic(Survival~Grade+Center, data = cancer.dataframe, shade=TRUE)
```

### Crabs

* Dataset Crabs (del paquete MASS) [Venables y Ripley, 2002]. Los autores inicialmente se transforman a una escala logarítmica y luego escriben que:

 “The data are very highly correlated and scatterplot matrices and brush plots [i.e. interactive graphics] are none too revealing.”. 

Utilizando gráficos generales, comente si la transformación logarítmica fue una buena idea y si está de acuerdo con su afirmación sobre las correlaciones.

```{r}
install.packages("MASS")
library(MASS)
head(crabs)
```

En base a los datos, lo primero que tendremos que hacer es pintar los pairs de las variables continuas, ya que las demas no aportan información para lo que queremos comprobar.

```{r}
pairs(crabs[4:8])
```

Definitivamente si que fue una buena idea la transformación logarítmica con las variables, ya que todas presenta una correlacion lineal total. 



# Como crear subgrupos de datos en R

Busca información sobre la function cut(). Para ilustrar su uso vamos a utilizar el dataset state.x77. Si no lo tienes instalado instala el paquete R-Datasets. Usa la función head() para ver como son tus datos.


* Extrae la columna Frost y asigna el resultado a la variable frost

* Tu nuevo objeto es un vector numérico. Ahora intenta agrupar los datos en frost en tres niveles. Para crear bins en tus datos puedes utilizar la función cut(). 


* ¿Que obtienes como nombres de los niveles?

* En la realidad no existen estados que tengan frost en días negativos. Esto es porque R añade un poco de padding. Prueba a solucionar el problema utilizando el parámetro include.lowest=TRUE en cut().

* Los nombres de los niveles no son demasiado informativos, especifica nuevos nombres para los niveles.

* Después de este paso has creado un factor que clasifica los estados en bajo, medio y alto según el numero de heladas. Ahora cuenta el número de estados que  hay en cada uno de los niveles. PISTA: utiliza la función table()

